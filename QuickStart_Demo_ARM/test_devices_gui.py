#!/usr/bin/env python3
"""
æ ‘è“æ´¾éº¦å…‹é£å’Œæ‘„åƒå¤´æµ‹è¯• GUI Demo
å¸¦å›¾å½¢ç•Œé¢çš„è®¾å¤‡æµ‹è¯•å·¥å…·
"""

import sys
import os
import subprocess
import threading
import time

try:
    from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                                  QHBoxLayout, QPushButton, QLabel, QTextEdit,
                                  QGroupBox, QProgressBar, QFrame, QComboBox)
    from PyQt5.QtCore import Qt, QTimer, pyqtSignal, QThread
    from PyQt5.QtGui import QImage, QPixmap, QFont
except ImportError:
    print("æ­£åœ¨å®‰è£… PyQt5...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "PyQt5", "--break-system-packages", "-q"])
    from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                                  QHBoxLayout, QPushButton, QLabel, QTextEdit,
                                  QGroupBox, QProgressBar, QFrame, QComboBox)
    from PyQt5.QtCore import Qt, QTimer, pyqtSignal, QThread
    from PyQt5.QtGui import QImage, QPixmap, QFont

try:
    import pyaudio
except ImportError:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "pyaudio", "--break-system-packages", "-q"])
    import pyaudio

try:
    import numpy as np
except ImportError:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "numpy", "--break-system-packages", "-q"])
    import numpy as np

try:
    import cv2
except ImportError:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "opencv-python", "--break-system-packages", "-q"])
    import cv2


class AudioThread(QThread):
    """éŸ³é¢‘å½•åˆ¶çº¿ç¨‹"""
    level_signal = pyqtSignal(int)
    status_signal = pyqtSignal(str)
    
    def __init__(self):
        super().__init__()
        self.running = False
        self.p = None
        self.stream = None
        
    def run(self):
        self.running = True
        try:
            self.p = pyaudio.PyAudio()
            
            # æŸ¥æ‰¾USBéº¦å…‹é£
            device_index = None
            for i in range(self.p.get_device_count()):
                info = self.p.get_device_info_by_index(i)
                if info['maxInputChannels'] > 0:
                    device_index = i
                    self.status_signal.emit(f"ä½¿ç”¨è®¾å¤‡: {info['name']}")
                    break
            
            if device_index is None:
                self.status_signal.emit("âŒ æœªæ‰¾åˆ°éº¦å…‹é£")
                return
            
            CHUNK = 1024
            FORMAT = pyaudio.paInt16
            CHANNELS = 1
            RATE = 16000
            
            self.stream = self.p.open(format=FORMAT,
                                      channels=CHANNELS,
                                      rate=RATE,
                                      input=True,
                                      input_device_index=device_index,
                                      frames_per_buffer=CHUNK)
            
            self.status_signal.emit("âœ… éº¦å…‹é£å·²å¯åŠ¨")
            
            while self.running:
                try:
                    data = self.stream.read(CHUNK, exception_on_overflow=False)
                    amplitude = max(abs(int.from_bytes(data[i:i+2], 'little', signed=True)) 
                                  for i in range(0, min(len(data), 200), 2))
                    level = min(100, int(amplitude / 327))
                    self.level_signal.emit(level)
                except Exception as e:
                    pass
                    
        except Exception as e:
            self.status_signal.emit(f"âŒ éº¦å…‹é£é”™è¯¯: {str(e)[:50]}")
        finally:
            self.cleanup()
    
    def cleanup(self):
        if self.stream:
            try:
                self.stream.stop_stream()
                self.stream.close()
            except:
                pass
        if self.p:
            try:
                self.p.terminate()
            except:
                pass
    
    def stop(self):
        self.running = False
        self.wait(1000)


class SpeakerThread(QThread):
    """å–‡å­æµ‹è¯•çº¿ç¨‹"""
    status_signal = pyqtSignal(str)
    finished_signal = pyqtSignal(bool)
    
    def __init__(self):
        super().__init__()
        self.p = None
        self.stream = None
        
    def run(self):
        try:
            self.p = pyaudio.PyAudio()
            
            # æ£€æŸ¥è¾“å‡ºè®¾å¤‡
            output_devices = []
            for i in range(self.p.get_device_count()):
                info = self.p.get_device_info_by_index(i)
                if info['maxOutputChannels'] > 0:
                    output_devices.append((i, info['name']))
            
            if not output_devices:
                self.status_signal.emit("âŒ æœªæ‰¾åˆ°è¾“å‡ºè®¾å¤‡")
                self.finished_signal.emit(False)
                return
            
            self.status_signal.emit("ğŸ”Š æ­£åœ¨æ’­æ”¾...")
            
            # è·å–é»˜è®¤è¾“å‡ºè®¾å¤‡æ”¯æŒçš„é‡‡æ ·ç‡
            default_output = self.p.get_default_output_device_info()
            RATE = int(default_output.get('defaultSampleRate', 48000))
            
            DURATION = 1.5
            FREQUENCY = 440
            
            t = np.linspace(0, DURATION, int(RATE * DURATION), False)
            envelope = np.ones_like(t)
            fade_samples = int(RATE * 0.05)
            envelope[:fade_samples] = np.linspace(0, 1, fade_samples)
            envelope[-fade_samples:] = np.linspace(1, 0, fade_samples)
            
            tone = np.sin(2 * np.pi * FREQUENCY * t) * envelope * 0.5
            audio_data = (tone * 32767).astype(np.int16).tobytes()
            
            self.stream = self.p.open(format=pyaudio.paInt16,
                                      channels=1,
                                      rate=RATE,
                                      output=True)
            
            self.stream.write(audio_data)
            
            self.status_signal.emit("âœ… æ’­æ”¾å®Œæˆ")
            self.finished_signal.emit(True)
            
        except Exception as e:
            self.status_signal.emit(f"âŒ é”™è¯¯: {str(e)[:30]}")
            self.finished_signal.emit(False)
        finally:
            self.cleanup()
    
    def cleanup(self):
        if self.stream:
            try:
                self.stream.stop_stream()
                self.stream.close()
            except:
                pass
        if self.p:
            try:
                self.p.terminate()
            except:
                pass


class CameraThread(QThread):
    """æ‘„åƒå¤´çº¿ç¨‹ - æ”¯æŒCSIå’ŒUSBæ‘„åƒå¤´"""
    frame_signal = pyqtSignal(QImage)
    status_signal = pyqtSignal(str)
    
    def __init__(self, camera_type="CSI", usb_device_index=0):
        super().__init__()
        self.running = False
        self.process = None
        self.cap = None
        self.camera_type = camera_type
        self.usb_device_index = usb_device_index
        
    def run(self):
        self.running = True
        if self.camera_type == "CSI":
            self.run_csi_camera()
        else:
            self.run_usb_camera()
    
    def run_csi_camera(self):
        """è¿è¡ŒCSIæ‘„åƒå¤´ (rpicam)"""
        try:
            result = subprocess.run(['rpicam-hello', '--list-cameras'],
                                   capture_output=True, text=True, timeout=3)
            
            if 'Available cameras' not in result.stdout:
                self.status_signal.emit("âŒ æœªæ£€æµ‹åˆ°CSIæ‘„åƒå¤´")
                return
            
            self.status_signal.emit("âœ… CSIæ‘„åƒå¤´å·²å¯åŠ¨")
            
            cmd = [
                'rpicam-vid', '-t', '0', '--inline', '--nopreview',
                '--width', '640', '--height', '480', '--framerate', '15',
                '--codec', 'mjpeg', '-o', '-'
            ]
            
            self.process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)
            
            buffer = b''
            while self.running and self.process.poll() is None:
                chunk = self.process.stdout.read(4096)
                if not chunk:
                    break
                buffer += chunk
                
                start = buffer.find(b'\xff\xd8')
                end = buffer.find(b'\xff\xd9')
                
                if start != -1 and end != -1 and end > start:
                    jpg = buffer[start:end+2]
                    buffer = buffer[end+2:]
                    
                    nparr = np.frombuffer(jpg, np.uint8)
                    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                    
                    if frame is not None:
                        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        h, w, ch = rgb.shape
                        qimg = QImage(rgb.data, w, h, ch * w, QImage.Format_RGB888)
                        self.frame_signal.emit(qimg.copy())
                        
        except subprocess.TimeoutExpired:
            self.status_signal.emit("âŒ CSIæ‘„åƒå¤´æ£€æµ‹è¶…æ—¶")
        except FileNotFoundError:
            self.status_signal.emit("âŒ rpicamæœªå®‰è£…")
        except Exception as e:
            self.status_signal.emit(f"âŒ CSIæ‘„åƒå¤´é”™è¯¯: {str(e)[:50]}")
        finally:
            self.cleanup()
    
    def run_usb_camera(self):
        """è¿è¡ŒUSBæ‘„åƒå¤´ (OpenCV)"""
        try:
            self.cap = cv2.VideoCapture(self.usb_device_index)
            
            if not self.cap.isOpened():
                self.status_signal.emit(f"âŒ æ— æ³•æ‰“å¼€USBæ‘„åƒå¤´ /dev/video{self.usb_device_index}")
                return
            
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 15)
            
            self.status_signal.emit(f"âœ… USBæ‘„åƒå¤´å·²å¯åŠ¨ (video{self.usb_device_index})")
            
            while self.running:
                ret, frame = self.cap.read()
                if not ret:
                    continue
                
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                h, w, ch = rgb.shape
                qimg = QImage(rgb.data, w, h, ch * w, QImage.Format_RGB888)
                self.frame_signal.emit(qimg.copy())
                
                time.sleep(0.033)  # ~30fps
                
        except Exception as e:
            self.status_signal.emit(f"âŒ USBæ‘„åƒå¤´é”™è¯¯: {str(e)[:50]}")
        finally:
            self.cleanup()
    
    def cleanup(self):
        if self.process:
            try:
                self.process.terminate()
                self.process.wait(timeout=1)
            except:
                try:
                    self.process.kill()
                except:
                    pass
        if self.cap:
            try:
                self.cap.release()
            except:
                pass
    
    def stop(self):
        self.running = False
        self.cleanup()
        self.wait(2000)


def detect_usb_cameras():
    """æ£€æµ‹å¯ç”¨çš„USBæ‘„åƒå¤´è®¾å¤‡"""
    cameras = []
    try:
        # ä½¿ç”¨v4l2-ctlè·å–è®¾å¤‡åˆ—è¡¨
        result = subprocess.run(['v4l2-ctl', '--list-devices'],
                               capture_output=True, text=True, timeout=5)
        output = result.stdout
        
        # è§£æè¾“å‡ºï¼ŒæŸ¥æ‰¾USBæ‘„åƒå¤´
        lines = output.split('\n')
        current_device = None
        first_video_found = False
        
        for line in lines:
            # è®¾å¤‡åç§°è¡Œï¼ˆä¸ä»¥ç©ºç™½å¼€å¤´ï¼‰
            if line and not line.startswith('\t') and not line.startswith(' '):
                current_device = line.strip()
                first_video_found = False
            # videoè®¾å¤‡è·¯å¾„è¡Œ
            elif line.strip().startswith('/dev/video') and not first_video_found:
                video_path = line.strip()
                video_num = int(video_path.replace('/dev/video', ''))
                
                # æ’é™¤éUSBæ‘„åƒå¤´è®¾å¤‡
                if current_device:
                    # æ’é™¤: CSIæ‘„åƒå¤´(rp1-cfe)ã€PISPåç«¯(pispbe)ã€è§£ç å™¨(hevc)
                    skip_keywords = ['rp1-cfe', 'pispbe', 'hevc-dec']
                    if any(kw in current_device.lower() for kw in skip_keywords):
                        continue
                    
                    # è¿™æ˜¯USBæ‘„åƒå¤´
                    device_name = current_device.split('(')[0].strip()
                    if ':' in device_name:
                        device_name = device_name.split(':')[0].strip()
                    cameras.append((video_num, f"{device_name} (video{video_num})"))
                    first_video_found = True  # æ¯ä¸ªè®¾å¤‡åªå–ç¬¬ä¸€ä¸ªvideoèŠ‚ç‚¹
                    
    except Exception as e:
        pass
    
    return cameras


class DeviceTestWindow(QMainWindow):
    """è®¾å¤‡æµ‹è¯•ä¸»çª—å£"""
    
    def __init__(self):
        super().__init__()
        self.audio_thread = None
        self.camera_thread = None
        self.speaker_thread = None
        self.init_ui()
        
    def init_ui(self):
        self.setWindowTitle("è®¾å¤‡æµ‹è¯•")
        self.setFixedSize(580, 320)  # é€‚é…å±å¹•ï¼Œå¢åŠ å®½åº¦ä»¥å®¹çº³å–‡å­æµ‹è¯•
        
        central = QWidget()
        self.setCentralWidget(central)
        layout = QHBoxLayout(central)
        
        # å·¦ä¾§ - æ‘„åƒå¤´
        camera_group = QGroupBox("ğŸ“· æ‘„åƒå¤´")
        camera_layout = QVBoxLayout(camera_group)
        
        # æ‘„åƒå¤´é€‰æ‹©ä¸‹æ‹‰æ¡†
        camera_select_layout = QHBoxLayout()
        self.camera_combo = QComboBox()
        self.camera_combo.setFixedHeight(24)
        self.refresh_cameras()
        camera_select_layout.addWidget(self.camera_combo, stretch=1)
        
        self.refresh_btn = QPushButton("ğŸ”„")
        self.refresh_btn.setFixedSize(28, 24)
        self.refresh_btn.clicked.connect(self.refresh_cameras)
        camera_select_layout.addWidget(self.refresh_btn)
        camera_layout.addLayout(camera_select_layout)
        
        self.camera_label = QLabel("ç‚¹å‡»å¯åŠ¨")
        self.camera_label.setFixedSize(240, 160)
        self.camera_label.setAlignment(Qt.AlignCenter)
        self.camera_label.setStyleSheet("background-color: #2d2d2d; color: white; border-radius: 4px; font-size: 11px;")
        camera_layout.addWidget(self.camera_label)
        
        self.camera_status = QLabel("æœªå¯åŠ¨")
        self.camera_status.setStyleSheet("font-size: 10px;")
        camera_layout.addWidget(self.camera_status)
        
        camera_btn_layout = QHBoxLayout()
        camera_btn_layout.setSpacing(2)
        self.camera_start_btn = QPushButton("â–¶")
        self.camera_start_btn.setFixedSize(40, 28)
        self.camera_start_btn.clicked.connect(self.start_camera)
        self.camera_stop_btn = QPushButton("â¹")
        self.camera_stop_btn.setFixedSize(40, 28)
        self.camera_stop_btn.clicked.connect(self.stop_camera)
        self.camera_stop_btn.setEnabled(False)
        self.camera_capture_btn = QPushButton("ğŸ“¸")
        self.camera_capture_btn.setFixedSize(40, 28)
        self.camera_capture_btn.clicked.connect(self.capture_photo)
        self.camera_capture_btn.setEnabled(False)
        camera_btn_layout.addWidget(self.camera_start_btn)
        camera_btn_layout.addWidget(self.camera_stop_btn)
        camera_btn_layout.addWidget(self.camera_capture_btn)
        camera_btn_layout.addStretch()
        camera_layout.addLayout(camera_btn_layout)
        
        layout.addWidget(camera_group, stretch=2)
        
        # ä¸­é—´ - éº¦å…‹é£
        audio_group = QGroupBox("ğŸ™ éº¦å…‹é£")
        audio_layout = QVBoxLayout(audio_group)
        
        self.audio_level = QProgressBar()
        self.audio_level.setOrientation(Qt.Vertical)
        self.audio_level.setMinimum(0)
        self.audio_level.setMaximum(100)
        self.audio_level.setValue(0)
        self.audio_level.setFixedSize(40, 150)
        self.audio_level.setStyleSheet("""
            QProgressBar {
                border: 2px solid #555;
                border-radius: 5px;
                background-color: #2d2d2d;
            }
            QProgressBar::chunk {
                background-color: #4CAF50;
            }
        """)
        
        level_layout = QHBoxLayout()
        level_layout.addStretch()
        level_layout.addWidget(self.audio_level)
        level_layout.addStretch()
        audio_layout.addLayout(level_layout)
        
        self.audio_value_label = QLabel("0%")
        self.audio_value_label.setAlignment(Qt.AlignCenter)
        self.audio_value_label.setStyleSheet("font-size: 11px;")
        audio_layout.addWidget(self.audio_value_label)
        
        self.audio_status = QLabel("æœªå¯åŠ¨")
        self.audio_status.setStyleSheet("font-size: 10px;")
        audio_layout.addWidget(self.audio_status)
        
        audio_btn_layout = QHBoxLayout()
        audio_btn_layout.setSpacing(2)
        self.audio_start_btn = QPushButton("â–¶")
        self.audio_start_btn.setFixedSize(40, 28)
        self.audio_start_btn.clicked.connect(self.start_audio)
        self.audio_stop_btn = QPushButton("â¹")
        self.audio_stop_btn.setFixedSize(40, 28)
        self.audio_stop_btn.clicked.connect(self.stop_audio)
        self.audio_stop_btn.setEnabled(False)
        audio_btn_layout.addWidget(self.audio_start_btn)
        audio_btn_layout.addWidget(self.audio_stop_btn)
        audio_layout.addLayout(audio_btn_layout)
        
        layout.addWidget(audio_group, stretch=1)
        
        # å³ä¾§ - å–‡å­
        speaker_group = QGroupBox("ğŸ”Š å–‡å­")
        speaker_layout = QVBoxLayout(speaker_group)
        
        self.speaker_icon = QLabel("ğŸ”ˆ")
        self.speaker_icon.setAlignment(Qt.AlignCenter)
        self.speaker_icon.setStyleSheet("font-size: 48px;")
        speaker_layout.addWidget(self.speaker_icon)
        
        self.speaker_status = QLabel("æœªæµ‹è¯•")
        self.speaker_status.setAlignment(Qt.AlignCenter)
        self.speaker_status.setStyleSheet("font-size: 10px;")
        speaker_layout.addWidget(self.speaker_status)
        
        self.speaker_test_btn = QPushButton("ğŸ”Š æµ‹è¯•")
        self.speaker_test_btn.setFixedHeight(28)
        self.speaker_test_btn.clicked.connect(self.test_speaker)
        speaker_layout.addWidget(self.speaker_test_btn)
        
        speaker_layout.addStretch()
        
        layout.addWidget(speaker_group, stretch=1)
        
        # æ ·å¼
        self.setStyleSheet("""
            QMainWindow {
                background-color: #1e1e1e;
            }
            QGroupBox {
                font-size: 12px;
                font-weight: bold;
                color: white;
                border: 1px solid #555;
                border-radius: 4px;
                margin-top: 8px;
                padding-top: 6px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px;
            }
            QPushButton {
                background-color: #0078d4;
                color: white;
                border: none;
                padding: 4px 8px;
                border-radius: 3px;
                font-size: 12px;
            }
            QPushButton:hover {
                background-color: #1084d8;
            }
            QPushButton:disabled {
                background-color: #555;
            }
            QLabel {
                color: white;
                font-size: 10px;
            }
            QComboBox {
                background-color: #3d3d3d;
                color: white;
                border: 1px solid #555;
                border-radius: 3px;
                padding: 2px 5px;
                font-size: 10px;
            }
            QComboBox::drop-down {
                border: none;
            }
            QComboBox QAbstractItemView {
                background-color: #3d3d3d;
                color: white;
                selection-background-color: #0078d4;
            }
        """)
    
    def refresh_cameras(self):
        """åˆ·æ–°æ‘„åƒå¤´åˆ—è¡¨"""
        self.camera_combo.clear()
        self.camera_combo.addItem("CSI æ‘„åƒå¤´", ("CSI", 0))
        
        usb_cameras = detect_usb_cameras()
        for idx, name in usb_cameras:
            self.camera_combo.addItem(name, ("USB", idx))
    
    def start_camera(self):
        if self.camera_thread and self.camera_thread.isRunning():
            return
        
        self.camera_status.setText("çŠ¶æ€: å¯åŠ¨ä¸­...")
        self.camera_start_btn.setEnabled(False)
        self.camera_combo.setEnabled(False)
        self.refresh_btn.setEnabled(False)
        
        # è·å–é€‰ä¸­çš„æ‘„åƒå¤´ç±»å‹
        camera_data = self.camera_combo.currentData()
        if camera_data:
            camera_type, device_index = camera_data
        else:
            camera_type, device_index = "CSI", 0
        
        self.camera_thread = CameraThread(camera_type, device_index)
        self.camera_thread.frame_signal.connect(self.update_camera_frame)
        self.camera_thread.status_signal.connect(self.update_camera_status)
        self.camera_thread.start()
        
        self.camera_stop_btn.setEnabled(True)
        self.camera_capture_btn.setEnabled(True)
    
    def stop_camera(self):
        if self.camera_thread:
            self.camera_thread.stop()
            self.camera_thread = None
        
        self.camera_label.setText("æ‘„åƒå¤´å·²åœæ­¢")
        self.camera_status.setText("çŠ¶æ€: å·²åœæ­¢")
        self.camera_start_btn.setEnabled(True)
        self.camera_stop_btn.setEnabled(False)
        self.camera_capture_btn.setEnabled(False)
        self.camera_combo.setEnabled(True)
        self.refresh_btn.setEnabled(True)
    
    def update_camera_frame(self, qimg):
        pixmap = QPixmap.fromImage(qimg)
        scaled = pixmap.scaled(self.camera_label.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
        self.camera_label.setPixmap(scaled)
    
    def update_camera_status(self, status):
        self.camera_status.setText(f"çŠ¶æ€: {status}")
        if "âŒ" in status:
            self.camera_start_btn.setEnabled(True)
            self.camera_stop_btn.setEnabled(False)
            self.camera_capture_btn.setEnabled(False)
            self.camera_combo.setEnabled(True)
            self.refresh_btn.setEnabled(True)
    
    def capture_photo(self):
        """æ‹ç…§ä¿å­˜"""
        try:
            filename = f"/home/gary/Desktop/photo_{int(time.time())}.jpg"
            camera_data = self.camera_combo.currentData()
            camera_type = camera_data[0] if camera_data else "CSI"
            
            if camera_type == "CSI":
                subprocess.run(['rpicam-still', '-o', filename, '-t', '500', '--nopreview'],
                              capture_output=True, timeout=5)
            else:
                # USBæ‘„åƒå¤´æ‹ç…§ - ä»å½“å‰æ˜¾ç¤ºçš„å›¾åƒä¿å­˜
                pixmap = self.camera_label.pixmap()
                if pixmap:
                    pixmap.save(filename, "JPEG")
            self.camera_status.setText(f"çŠ¶æ€: ç…§ç‰‡å·²ä¿å­˜åˆ°æ¡Œé¢")
        except Exception as e:
            self.camera_status.setText(f"çŠ¶æ€: æ‹ç…§å¤±è´¥")
    
    def start_audio(self):
        if self.audio_thread and self.audio_thread.isRunning():
            return
        
        self.audio_status.setText("çŠ¶æ€: å¯åŠ¨ä¸­...")
        self.audio_start_btn.setEnabled(False)
        
        self.audio_thread = AudioThread()
        self.audio_thread.level_signal.connect(self.update_audio_level)
        self.audio_thread.status_signal.connect(self.update_audio_status)
        self.audio_thread.start()
        
        self.audio_stop_btn.setEnabled(True)
    
    def stop_audio(self):
        if self.audio_thread:
            self.audio_thread.stop()
            self.audio_thread = None
        
        self.audio_level.setValue(0)
        self.audio_value_label.setText("éŸ³é‡: 0")
        self.audio_status.setText("çŠ¶æ€: å·²åœæ­¢")
        self.audio_start_btn.setEnabled(True)
        self.audio_stop_btn.setEnabled(False)
    
    def update_audio_level(self, level):
        self.audio_level.setValue(level)
        self.audio_value_label.setText(f"éŸ³é‡: {level}%")
    
    def update_audio_status(self, status):
        self.audio_status.setText(f"çŠ¶æ€: {status}")
        if "âŒ" in status:
            self.audio_start_btn.setEnabled(True)
            self.audio_stop_btn.setEnabled(False)
    
    def test_speaker(self):
        """æµ‹è¯•å–‡å­"""
        if self.speaker_thread and self.speaker_thread.isRunning():
            return
        
        self.speaker_status.setText("çŠ¶æ€: å‡†å¤‡ä¸­...")
        self.speaker_test_btn.setEnabled(False)
        self.speaker_icon.setText("ğŸ”Š")
        
        self.speaker_thread = SpeakerThread()
        self.speaker_thread.status_signal.connect(self.update_speaker_status)
        self.speaker_thread.finished_signal.connect(self.on_speaker_finished)
        self.speaker_thread.start()
    
    def update_speaker_status(self, status):
        self.speaker_status.setText(f"çŠ¶æ€: {status}")
    
    def on_speaker_finished(self, success):
        self.speaker_test_btn.setEnabled(True)
        if success:
            self.speaker_icon.setText("ğŸ”Š")
        else:
            self.speaker_icon.setText("ğŸ”‡")
    
    def closeEvent(self, event):
        self.stop_camera()
        self.stop_audio()
        event.accept()


def main():
    # æŠ‘åˆ¶ALSAè­¦å‘Šå’ŒQtæ’ä»¶å†²çª
    os.environ['PYTHONWARNINGS'] = 'ignore'
    os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = ''  # ä½¿ç”¨ç³»ç»ŸQtæ’ä»¶
    
    app = QApplication(sys.argv)
    app.setStyle('Fusion')
    
    window = DeviceTestWindow()
    window.show()
    
    sys.exit(app.exec_())


if __name__ == "__main__":
    main()
